{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe2a746a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  10 of 10 completed\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from nltk import CFG\n",
    "\n",
    "# List of 10 tech stocks\n",
    "tech_stocks = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'TSLA', 'NVDA', 'NFLX', 'ADBE', 'INTC']\n",
    "\n",
    "# Download data for these stocks\n",
    "intraday_data = yf.download(tickers=tech_stocks, period='5d', interval='1m')\n",
    "\n",
    "# Save to CSV for further analysis (optional)\n",
    "intraday_data.to_csv(f'tech_stocks_intraday_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee56b0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_8848\\3940698456.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adj_close_data.fillna(method='ffill', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>INTC</th>\n",
       "      <th>META</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NFLX</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>TSLA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-09-30 13:31:00+00:00</th>\n",
       "      <td>0.409591</td>\n",
       "      <td>0.122715</td>\n",
       "      <td>-0.026313</td>\n",
       "      <td>0.415044</td>\n",
       "      <td>0.167859</td>\n",
       "      <td>0.014131</td>\n",
       "      <td>0.324643</td>\n",
       "      <td>0.100054</td>\n",
       "      <td>0.537281</td>\n",
       "      <td>0.995144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-30 13:32:00+00:00</th>\n",
       "      <td>-0.125025</td>\n",
       "      <td>0.085609</td>\n",
       "      <td>0.444065</td>\n",
       "      <td>0.370776</td>\n",
       "      <td>-0.167578</td>\n",
       "      <td>0.307701</td>\n",
       "      <td>0.133169</td>\n",
       "      <td>0.074261</td>\n",
       "      <td>-0.053073</td>\n",
       "      <td>0.116293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-30 13:33:00+00:00</th>\n",
       "      <td>0.250357</td>\n",
       "      <td>0.058329</td>\n",
       "      <td>-0.181108</td>\n",
       "      <td>-0.048448</td>\n",
       "      <td>-0.062943</td>\n",
       "      <td>0.014107</td>\n",
       "      <td>0.127794</td>\n",
       "      <td>-0.013770</td>\n",
       "      <td>0.036021</td>\n",
       "      <td>0.017602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-30 13:34:00+00:00</th>\n",
       "      <td>0.018087</td>\n",
       "      <td>-0.065089</td>\n",
       "      <td>-0.034149</td>\n",
       "      <td>-0.101482</td>\n",
       "      <td>-0.441321</td>\n",
       "      <td>0.047597</td>\n",
       "      <td>-0.106652</td>\n",
       "      <td>0.063969</td>\n",
       "      <td>0.144005</td>\n",
       "      <td>0.384194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-30 13:35:00+00:00</th>\n",
       "      <td>-0.267770</td>\n",
       "      <td>0.127345</td>\n",
       "      <td>0.144552</td>\n",
       "      <td>-0.141018</td>\n",
       "      <td>0.021511</td>\n",
       "      <td>-0.010571</td>\n",
       "      <td>0.095638</td>\n",
       "      <td>0.289352</td>\n",
       "      <td>0.058523</td>\n",
       "      <td>-0.385003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-04 19:55:00+00:00</th>\n",
       "      <td>0.142807</td>\n",
       "      <td>-0.056208</td>\n",
       "      <td>0.107491</td>\n",
       "      <td>0.035878</td>\n",
       "      <td>-0.088509</td>\n",
       "      <td>0.080190</td>\n",
       "      <td>-0.103192</td>\n",
       "      <td>-0.119295</td>\n",
       "      <td>0.016576</td>\n",
       "      <td>0.019956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-04 19:56:00+00:00</th>\n",
       "      <td>-0.052236</td>\n",
       "      <td>0.042425</td>\n",
       "      <td>0.013427</td>\n",
       "      <td>-0.020902</td>\n",
       "      <td>0.110740</td>\n",
       "      <td>-0.026002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004171</td>\n",
       "      <td>0.016005</td>\n",
       "      <td>-0.039947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-04 19:57:00+00:00</th>\n",
       "      <td>0.088207</td>\n",
       "      <td>0.103558</td>\n",
       "      <td>0.104674</td>\n",
       "      <td>0.095813</td>\n",
       "      <td>-0.066377</td>\n",
       "      <td>0.075498</td>\n",
       "      <td>0.036034</td>\n",
       "      <td>0.044445</td>\n",
       "      <td>0.015923</td>\n",
       "      <td>-0.006043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-04 19:58:00+00:00</th>\n",
       "      <td>-0.033048</td>\n",
       "      <td>-0.030541</td>\n",
       "      <td>0.010727</td>\n",
       "      <td>-0.008973</td>\n",
       "      <td>-0.022135</td>\n",
       "      <td>-0.031013</td>\n",
       "      <td>-0.038403</td>\n",
       "      <td>-0.026378</td>\n",
       "      <td>-0.055923</td>\n",
       "      <td>0.022006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-04 19:59:00+00:00</th>\n",
       "      <td>-0.035265</td>\n",
       "      <td>-0.064060</td>\n",
       "      <td>0.010726</td>\n",
       "      <td>-0.047865</td>\n",
       "      <td>0.044288</td>\n",
       "      <td>-0.074625</td>\n",
       "      <td>-0.055280</td>\n",
       "      <td>-0.112479</td>\n",
       "      <td>-0.016015</td>\n",
       "      <td>-0.016002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1948 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker                         AAPL      ADBE      AMZN     GOOGL      INTC  \\\n",
       "Datetime                                                                      \n",
       "2024-09-30 13:31:00+00:00  0.409591  0.122715 -0.026313  0.415044  0.167859   \n",
       "2024-09-30 13:32:00+00:00 -0.125025  0.085609  0.444065  0.370776 -0.167578   \n",
       "2024-09-30 13:33:00+00:00  0.250357  0.058329 -0.181108 -0.048448 -0.062943   \n",
       "2024-09-30 13:34:00+00:00  0.018087 -0.065089 -0.034149 -0.101482 -0.441321   \n",
       "2024-09-30 13:35:00+00:00 -0.267770  0.127345  0.144552 -0.141018  0.021511   \n",
       "...                             ...       ...       ...       ...       ...   \n",
       "2024-10-04 19:55:00+00:00  0.142807 -0.056208  0.107491  0.035878 -0.088509   \n",
       "2024-10-04 19:56:00+00:00 -0.052236  0.042425  0.013427 -0.020902  0.110740   \n",
       "2024-10-04 19:57:00+00:00  0.088207  0.103558  0.104674  0.095813 -0.066377   \n",
       "2024-10-04 19:58:00+00:00 -0.033048 -0.030541  0.010727 -0.008973 -0.022135   \n",
       "2024-10-04 19:59:00+00:00 -0.035265 -0.064060  0.010726 -0.047865  0.044288   \n",
       "\n",
       "Ticker                         META      MSFT      NFLX      NVDA      TSLA  \n",
       "Datetime                                                                     \n",
       "2024-09-30 13:31:00+00:00  0.014131  0.324643  0.100054  0.537281  0.995144  \n",
       "2024-09-30 13:32:00+00:00  0.307701  0.133169  0.074261 -0.053073  0.116293  \n",
       "2024-09-30 13:33:00+00:00  0.014107  0.127794 -0.013770  0.036021  0.017602  \n",
       "2024-09-30 13:34:00+00:00  0.047597 -0.106652  0.063969  0.144005  0.384194  \n",
       "2024-09-30 13:35:00+00:00 -0.010571  0.095638  0.289352  0.058523 -0.385003  \n",
       "...                             ...       ...       ...       ...       ...  \n",
       "2024-10-04 19:55:00+00:00  0.080190 -0.103192 -0.119295  0.016576  0.019956  \n",
       "2024-10-04 19:56:00+00:00 -0.026002  0.000000 -0.004171  0.016005 -0.039947  \n",
       "2024-10-04 19:57:00+00:00  0.075498  0.036034  0.044445  0.015923 -0.006043  \n",
       "2024-10-04 19:58:00+00:00 -0.031013 -0.038403 -0.026378 -0.055923  0.022006  \n",
       "2024-10-04 19:59:00+00:00 -0.074625 -0.055280 -0.112479 -0.016015 -0.016002  \n",
       "\n",
       "[1948 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_close_data = intraday_data['Adj Close']\n",
    "# Check if there are still missing values\n",
    "#print(adj_close_data.isnull().sum())\n",
    "# Display the first few rows\n",
    "adj_close_data.fillna(method='ffill', inplace=True)\n",
    "adj_close_data\n",
    "\n",
    "# Calculate the percentage change for each stock\n",
    "pct_change_data = adj_close_data.pct_change() * 100  # Convert to percentage\n",
    "\n",
    "# Display the first few rows of percentage change data\n",
    "pct_change_data.dropna(inplace=True)\n",
    "\n",
    "pct_change_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cebbfd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker                    AAPL ADBE AMZN GOOGL INTC META MSFT NFLX NVDA TSLA\n",
      "Datetime                                                                    \n",
      "2024-09-30 13:31:00+00:00    A    A    D     A    A    B    A    A    A    A\n",
      "2024-09-30 13:32:00+00:00    E    A    A     A    E    A    A    A    D    A\n",
      "2024-09-30 13:33:00+00:00    A    A    E     E    D    C    A    D    B    C\n",
      "2024-09-30 13:34:00+00:00    B    E    D     E    E    B    E    A    A    A\n",
      "2024-09-30 13:35:00+00:00    E    A    A     E    C    D    A    A    B    E\n"
     ]
    }
   ],
   "source": [
    "# Use quantiles to classify the data\n",
    "# Use quantiles to classify the data into A, B, C, D, E\n",
    "def classify_quantiles(pct_change, q1, q2, q3, q4):\n",
    "    if pct_change > q4:\n",
    "        return 'A'  # Highest range\n",
    "    elif pct_change > q3:\n",
    "        return 'B'  # Second highest range\n",
    "    elif pct_change > q2:\n",
    "        return 'C'  # Middle range\n",
    "    elif pct_change > q1:\n",
    "        return 'D'  # Second lowest range\n",
    "    else:\n",
    "        return 'E'  # Lowest range\n",
    "\n",
    "# Apply quantile-based classification to each ticker\n",
    "classified_data_quantiles = pct_change_data.copy()\n",
    "\n",
    "for ticker in pct_change_data.columns:\n",
    "    q1 = pct_change_data[ticker].quantile(0.2)\n",
    "    q2 = pct_change_data[ticker].quantile(0.4)\n",
    "    q3 = pct_change_data[ticker].quantile(0.6)\n",
    "    q4 = pct_change_data[ticker].quantile(0.8)\n",
    "    \n",
    "    # Apply classification for each stock\n",
    "    classified_data_quantiles[ticker] = pct_change_data[ticker].apply(classify_quantiles, args=(q1, q2, q3, q4))\n",
    "\n",
    "# Display the classified data\n",
    "print(classified_data_quantiles.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e90dbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Sequence for AAPL: ['A', 'E', 'A', 'B', 'E', 'A', 'C', 'A', 'B', 'D', 'E', 'D', 'A', 'E', 'A', 'E', 'A', 'C', 'E', 'E']\n"
     ]
    }
   ],
   "source": [
    "# Create continuous sequences for each stock\n",
    "def create_continuous_sequences(data):\n",
    "    continuous_sequences = {}\n",
    "    for ticker in data.columns:\n",
    "        stock_data = data[ticker].tolist()\n",
    "        continuous_sequences[ticker] = stock_data\n",
    "    return continuous_sequences\n",
    "\n",
    "continuous_sequences = create_continuous_sequences(classified_data_quantiles)\n",
    "print(\"Continuous Sequence for AAPL:\", continuous_sequences['AAPL'][:20])  # Display first 20 tokens for AAPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66771db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (A A))\n",
      "(S (E E))\n",
      "(S (A A))\n",
      "(S (B B))\n",
      "(S (E E))\n"
     ]
    }
   ],
   "source": [
    "# Grammar Definition (CFG)\n",
    "grammar = CFG.fromstring(\"\"\"\n",
    "    S -> A S | B S | C S | D S | E S | A | B | C | D | E\n",
    "    A -> 'A'\n",
    "    B -> 'B'\n",
    "    C -> 'C'\n",
    "    D -> 'D'\n",
    "    E -> 'E'\n",
    "\"\"\")\n",
    "parser = nltk.ChartParser(grammar)\n",
    "\n",
    "# Parsing function for stock sequences\n",
    "def parse_sequences(sequences, parser):\n",
    "    parsed_trees = {}\n",
    "    for stock, seq in sequences.items():\n",
    "        stock_parsed_trees = []\n",
    "        for token_sequence in seq:\n",
    "            trees = list(parser.parse(token_sequence))\n",
    "            stock_parsed_trees.extend(trees)\n",
    "        parsed_trees[stock] = stock_parsed_trees\n",
    "    return parsed_trees\n",
    "\n",
    "parsed_trees = parse_sequences(continuous_sequences, parser)\n",
    "\n",
    "for tree in parsed_trees['AAPL'][:5]:  # Displaying the first 5 parse trees for AAPL\n",
    "    print(tree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b5870b",
   "metadata": {},
   "source": [
    "# Create a base-line training with transformer without CFG Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "648eba55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing AAPL, sequence length: 1948\n",
      "Processing sequence of length: 1948\n",
      "Processing ADBE, sequence length: 1948\n",
      "Processing sequence of length: 1948\n",
      "Processing AMZN, sequence length: 1948\n",
      "Processing sequence of length: 1948\n",
      "Processing GOOGL, sequence length: 1948\n",
      "Processing sequence of length: 1948\n",
      "Processing INTC, sequence length: 1948\n",
      "Processing sequence of length: 1948\n",
      "Processing META, sequence length: 1948\n",
      "Processing sequence of length: 1948\n",
      "Processing MSFT, sequence length: 1948\n",
      "Processing sequence of length: 1948\n",
      "Processing NFLX, sequence length: 1948\n",
      "Processing sequence of length: 1948\n",
      "Processing NVDA, sequence length: 1948\n",
      "Processing sequence of length: 1948\n",
      "Processing TSLA, sequence length: 1948\n",
      "Processing sequence of length: 1948\n",
      "Total input-output pairs created: 19280\n",
      "Sample 1 - Input: [0, 4, 0, 1, 4, 0, 2, 0, 1, 3, 4, 3, 0, 4, 0, 4, 0, 2, 4, 4], Output: 4\n",
      "Sample 2 - Input: [4, 0, 1, 4, 0, 2, 0, 1, 3, 4, 3, 0, 4, 0, 4, 0, 2, 4, 4, 4], Output: 2\n",
      "Sample 3 - Input: [0, 1, 4, 0, 2, 0, 1, 3, 4, 3, 0, 4, 0, 4, 0, 2, 4, 4, 4, 2], Output: 0\n",
      "Sample 4 - Input: [1, 4, 0, 2, 0, 1, 3, 4, 3, 0, 4, 0, 4, 0, 2, 4, 4, 4, 2, 0], Output: 4\n",
      "Sample 5 - Input: [4, 0, 2, 0, 1, 3, 4, 3, 0, 4, 0, 4, 0, 2, 4, 4, 4, 2, 0, 4], Output: 2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Padding function for sequences\n",
    "def pad_sequence(seq, seq_length, pad_value):\n",
    "    if len(seq) < seq_length:\n",
    "        return [pad_value] * (seq_length - len(seq)) + seq\n",
    "    return seq\n",
    "\n",
    "# Create input-output pairs with padding where necessary\n",
    "def create_input_output_pairs(sequence, seq_length=20, pad_value=None):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    \n",
    "    print(f\"Processing sequence of length: {len(sequence)}\")\n",
    "    \n",
    "    if len(sequence) >= seq_length + 1:\n",
    "        for i in range(len(sequence) - seq_length):\n",
    "            input_chunk = sequence[i:i + seq_length]\n",
    "            output_token = sequence[i + seq_length]\n",
    "            inputs.append(input_chunk)\n",
    "            outputs.append(output_token)\n",
    "    else:\n",
    "        print(f\"Sequence too short, length: {len(sequence)}. Padding applied.\")\n",
    "        padded_seq = pad_sequence(sequence, seq_length, pad_value)\n",
    "        inputs.append(padded_seq)\n",
    "        outputs.append(sequence[-1])  # Use the last real token as the output\n",
    "    \n",
    "    return inputs, outputs\n",
    "\n",
    "# Example token-to-index conversion dictionary including padding\n",
    "token_to_idx = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, '<PAD>': 5}\n",
    "pad_value = token_to_idx['<PAD>']  # Padding with a special token '<PAD>'\n",
    "# Process the continuous_sequences to generate input-output pairs\n",
    "input_sequences = []\n",
    "output_sequences = []\n",
    "\n",
    "for ticker, sequence in continuous_sequences.items():\n",
    "    print(f\"Processing {ticker}, sequence length: {len(sequence)}\")\n",
    "    inputs, outputs = create_input_output_pairs(sequence, seq_length=20, pad_value=pad_value)\n",
    "    input_sequences.extend(inputs)\n",
    "    output_sequences.extend(outputs)\n",
    "\n",
    "# Convert input/output to numeric for easier model training\n",
    "input_sequences = [[token_to_idx[token] for token in seq] for seq in input_sequences]\n",
    "output_sequences = [token_to_idx[token] for token in output_sequences]\n",
    "\n",
    "# Check how many input-output pairs were created\n",
    "print(f\"Total input-output pairs created: {len(input_sequences)}\")\n",
    "\n",
    "# Print a few sample input-output pairs for inspection\n",
    "for i in range(5):\n",
    "    print(f\"Sample {i + 1} - Input: {input_sequences[i]}, Output: {output_sequences[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cacb0d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.6043064816858759\n",
      "Epoch 2/10, Loss: 1.5871620645661573\n",
      "Epoch 3/10, Loss: 1.5838352602547134\n",
      "Epoch 4/10, Loss: 1.5812721850961076\n",
      "Epoch 5/10, Loss: 1.5801316294432675\n",
      "Epoch 6/10, Loss: 1.5791233211632092\n",
      "Epoch 7/10, Loss: 1.5784592225343854\n",
      "Epoch 8/10, Loss: 1.5785940712418298\n",
      "Epoch 9/10, Loss: 1.57769234744345\n",
      "Epoch 10/10, Loss: 1.5782311212472402\n",
      "Test Accuracy: 26.14%\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test sets\n",
    "train_inputs, test_inputs, train_outputs, test_outputs = train_test_split(\n",
    "    input_sequences, output_sequences, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "train_inputs = torch.tensor(train_inputs, dtype=torch.long)\n",
    "train_outputs = torch.tensor(train_outputs, dtype=torch.long)\n",
    "test_inputs = torch.tensor(test_inputs, dtype=torch.long)\n",
    "test_outputs = torch.tensor(test_outputs, dtype=torch.long)\n",
    "\n",
    "# Create Dataset and DataLoader\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, inputs, outputs):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.outputs[idx]\n",
    "\n",
    "train_dataset = StockDataset(train_inputs, train_outputs)\n",
    "test_dataset = StockDataset(test_inputs, test_outputs)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# Define Transformer Model for Sequence Prediction\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=64, nhead=2, num_encoder_layers=2, dim_feedforward=128, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model, nhead=nhead, num_encoder_layers=num_encoder_layers, dim_feedforward=dim_feedforward, dropout=dropout\n",
    "        )\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "        self.src_mask = None\n",
    "\n",
    "    def forward(self, src):\n",
    "        # Embed the input tokens\n",
    "        src = self.embedding(src)\n",
    "        # Create the source mask\n",
    "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "            self.src_mask = self.generate_square_subsequent_mask(len(src)).to(src.device)\n",
    "        # Apply the transformer model\n",
    "        output = self.transformer(src, src, src_mask=self.src_mask)\n",
    "        # Output the final token predictions\n",
    "        output = self.fc_out(output[-1])  # Take the final output from the sequence\n",
    "        return output\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)\n",
    "        return mask\n",
    "\n",
    "# Model Parameters\n",
    "vocab_size = len(token_to_idx)\n",
    "model = TransformerModel(vocab_size)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training Loop\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs.T)  # Transpose for transformer (batch, seq_len) -> (seq_len, batch)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss/len(train_loader)}\")\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, criterion, optimizer, epochs=10)\n",
    "\n",
    "# Evaluation Loop\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            outputs = model(inputs.T)  # Transpose for transformer\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "    accuracy = correct / total\n",
    "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a65e78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
